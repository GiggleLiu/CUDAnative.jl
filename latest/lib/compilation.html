<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Compilation &amp; Execution · CUDAnative.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>CUDAnative.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../index.html">Home</a></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="../man/usage.html">Usage</a></li><li><a class="toctext" href="../man/troubleshooting.html">Troubleshooting</a></li><li><a class="toctext" href="../man/performance.html">Performance</a></li><li><a class="toctext" href="../man/hacking.html">Hacking</a></li></ul></li><li><span class="toctext">Library</span><ul><li class="current"><a class="toctext" href="compilation.html">Compilation &amp; Execution</a><ul class="internal"></ul></li><li><a class="toctext" href="reflection.html">Reflection</a></li><li><a class="toctext" href="profiling.html">Profiling</a></li><li><span class="toctext">Device Code</span><ul><li><a class="toctext" href="device/intrinsics.html">Intrinsics</a></li><li><a class="toctext" href="device/array.html">Arrays</a></li><li><a class="toctext" href="device/libdevice.html">libdevice</a></li></ul></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Library</li><li><a href="compilation.html">Compilation &amp; Execution</a></li></ul><a class="edit-page" href="https://github.com/github.com/JuliaGPU/CUDAnative.jl.git/blob/master/docs/src/lib/compilation.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Compilation &amp; Execution</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Compilation-and-Execution-1" href="#Compilation-and-Execution-1">Compilation &amp; Execution</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.@cuda" href="#CUDAnative.@cuda"><code>CUDAnative.@cuda</code></a> — <span class="docstring-category">Macro</span>.</div><div><div><pre><code class="language-none">@cuda [kwargs...] func(args...)</code></pre><p>High-level interface for calling functions on a GPU, queues a kernel launch on the current context. The <code>@cuda</code> macro should prefix a kernel invocation, with one of the following arguments in the <code>kwargs</code> position:</p><p>Affecting the kernel launch:</p><ul><li>threads (defaults to 1)</li><li>blocks (defaults to 1)</li><li>shmem (defaults to 0)</li><li>stream (defaults to the default stream)</li></ul><p>Affecting the kernel compilation:</p><ul><li>minthreads: the required number of threads in a thread block.</li><li>maxthreads: the maximum number of threads in a thread block.</li><li>blocks<em>per</em>sm: a minimum number of thread blocks to be scheduled on a single multiprocessor.</li><li>maxregs: the maximum number of registers to be allocated to a single thread (only supported on LLVM 4.0+)</li><li>alias: an identifier that will be used for naming the kernel in generated code (useful for profiling, debugging, ...)</li></ul><p>Note that, contrary to with CUDA C, you can invoke the same kernel multiple times with different compilation parameters. New code will be generated automatically.</p><p>The <code>func</code> argument should be a valid Julia function. Its return values will be ignored, by means of a wrapper. The function will be compiled to a CUDA function upon first use, and to a certain extent arguments will be converted and managed automatically (see <a href="compilation.html#CUDAnative.cudaconvert"><code>cudaconvert</code></a>). Finally, a call to <code>cudacall</code> is performed, scheduling the compiled function for execution on the GPU.</p></div></div><a class="source-link" target="_blank" href="https://github.com/github.com/JuliaGPU/CUDAnative.jl.git/blob/98a7f2fe30d98f8ef6ce617f43b080f5f6d032c8/src/execution.jl#L67-L98">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.cudaconvert" href="#CUDAnative.cudaconvert"><code>CUDAnative.cudaconvert</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">cudaconvert(x)</code></pre><p>This function is called for every argument to be passed to a kernel, allowing it to be converted to a GPU-friendly format. By default, the function does nothing and returns the input object <code>x</code> as-is.</p><p>For <code>CuArray</code> objects, a corresponding <code>CuDeviceArray</code> object in global space is returned, which implements GPU-compatible array functionality.</p></div></div><a class="source-link" target="_blank" href="https://github.com/github.com/JuliaGPU/CUDAnative.jl.git/blob/98a7f2fe30d98f8ef6ce617f43b080f5f6d032c8/src/execution.jl#L8-L17">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CUDAnative.nearest_warpsize" href="#CUDAnative.nearest_warpsize"><code>CUDAnative.nearest_warpsize</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Return the nearest number of threads that is a multiple of the warp size of a device:</p><pre><code class="language-none">nearest_warpsize(dev::CuDevice, threads::Integer)</code></pre><p>This is a common requirement, eg. when using shuffle intrinsics.</p></div></div><a class="source-link" target="_blank" href="https://github.com/github.com/JuliaGPU/CUDAnative.jl.git/blob/98a7f2fe30d98f8ef6ce617f43b080f5f6d032c8/src/execution.jl#L239-L245">source</a></section><footer><hr/><a class="previous" href="../man/hacking.html"><span class="direction">Previous</span><span class="title">Hacking</span></a><a class="next" href="reflection.html"><span class="direction">Next</span><span class="title">Reflection</span></a></footer></article></body></html>
